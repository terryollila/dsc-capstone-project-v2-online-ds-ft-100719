{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrubbing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading back in data that was created in 'obtaining' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good = pd.read_csv('df_good.csv')\n",
    "df_bad = pd.read_csv('df_bad.csv')\n",
    "rotten_df = pd.read_csv('rotten_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_good = pd.read_csv('df_good_obtain.csv')\n",
    "# df_bad = pd.read_csv('df_bad_obtain.csv')\n",
    "# rotten_df = pd.read_csv('rotten_df_obtain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rotten_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_df.columns = ['titles', 'titles_formatted', 'rotten_scores', \n",
    "                     'scripts', 'all_together_now', 'no_stop', 'just_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>titles_formatted</th>\n",
       "      <th>rotten_scores</th>\n",
       "      <th>scripts</th>\n",
       "      <th>all_together_now</th>\n",
       "      <th>no_stop</th>\n",
       "      <th>just_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_gallows_act_ii</td>\n",
       "      <td>gallows-act-ii-the</td>\n",
       "      <td>0</td>\n",
       "      <td>['\\n\\n                        1', ' - Do it.',...</td>\n",
       "      <td>['\\n\\n                        1', ' - Do it.',...</td>\n",
       "      <td>['\\n\\n 1', ' - it.', ' - right.', ' oh, gosh....</td>\n",
       "      <td>nn 1 right oh gosh oh gosh bro charlie mexica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>portals</td>\n",
       "      <td>portals</td>\n",
       "      <td>0</td>\n",
       "      <td>['\\n\\n                        1', ' [boulderli...</td>\n",
       "      <td>['\\n\\n                        1', ' [boulderli...</td>\n",
       "      <td>['\\n\\n 1', ' [boulderlight pictures theme]', ...</td>\n",
       "      <td>nn 1 boulderlight pictures theme bloody disgu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mob_town</td>\n",
       "      <td>mob-town</td>\n",
       "      <td>0</td>\n",
       "      <td>['\\n\\n                        1', ' Police rai...</td>\n",
       "      <td>['\\n\\n                        1', ' Police rai...</td>\n",
       "      <td>['\\n\\n 1', ' police raid organized crime meet...</td>\n",
       "      <td>nn 1 police raid organized crime meeting home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solis</td>\n",
       "      <td>solis</td>\n",
       "      <td>0</td>\n",
       "      <td>['\\n\\n                        1', ' [EERIE]', ...</td>\n",
       "      <td>['\\n\\n                        1', ' [EERIE]', ...</td>\n",
       "      <td>['\\n\\n 1', ' [eerie]', ' woman: come in, 2024...</td>\n",
       "      <td>nn 1 eerie woman come 2024 hathor 18 confirmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>welcome_to_curiosity</td>\n",
       "      <td>welcome-to-curiosity</td>\n",
       "      <td>0</td>\n",
       "      <td>['\\n\\n                        Help!', ' Someon...</td>\n",
       "      <td>['\\n\\n                        Help!', ' Someon...</td>\n",
       "      <td>['\\n\\n help!', ' help!', ' help!', ' paging d...</td>\n",
       "      <td>nn help help help paging dr jones paging dr j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 titles      titles_formatted  rotten_scores  \\\n",
       "0    the_gallows_act_ii    gallows-act-ii-the              0   \n",
       "1               portals               portals              0   \n",
       "2              mob_town              mob-town              0   \n",
       "3                 solis                 solis              0   \n",
       "4  welcome_to_curiosity  welcome-to-curiosity              0   \n",
       "\n",
       "                                             scripts  \\\n",
       "0  ['\\n\\n                        1', ' - Do it.',...   \n",
       "1  ['\\n\\n                        1', ' [boulderli...   \n",
       "2  ['\\n\\n                        1', ' Police rai...   \n",
       "3  ['\\n\\n                        1', ' [EERIE]', ...   \n",
       "4  ['\\n\\n                        Help!', ' Someon...   \n",
       "\n",
       "                                    all_together_now  \\\n",
       "0  ['\\n\\n                        1', ' - Do it.',...   \n",
       "1  ['\\n\\n                        1', ' [boulderli...   \n",
       "2  ['\\n\\n                        1', ' Police rai...   \n",
       "3  ['\\n\\n                        1', ' [EERIE]', ...   \n",
       "4  ['\\n\\n                        Help!', ' Someon...   \n",
       "\n",
       "                                             no_stop  \\\n",
       "0   ['\\n\\n 1', ' - it.', ' - right.', ' oh, gosh....   \n",
       "1   ['\\n\\n 1', ' [boulderlight pictures theme]', ...   \n",
       "2   ['\\n\\n 1', ' police raid organized crime meet...   \n",
       "3   ['\\n\\n 1', ' [eerie]', ' woman: come in, 2024...   \n",
       "4   ['\\n\\n help!', ' help!', ' help!', ' paging d...   \n",
       "\n",
       "                                          just_words  \n",
       "0   nn 1 right oh gosh oh gosh bro charlie mexica...  \n",
       "1   nn 1 boulderlight pictures theme bloody disgu...  \n",
       "2   nn 1 police raid organized crime meeting home...  \n",
       "3   nn 1 eerie woman come 2024 hathor 18 confirmi...  \n",
       "4   nn help help help paging dr jones paging dr j...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_it(text, punct=False):\n",
    "    \"\"\"Removes stop words and punctuation.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        text: string\n",
    "            Text to have stop words and punctuation removed from..\n",
    "            \n",
    "        punct: bool\n",
    "            If set to true, will also remove punctuation.\n",
    "            \n",
    "    Returns:\n",
    "        String of words with stop words removed, and punctuation removed if\n",
    "        selected.\"\"\"\n",
    "    \n",
    "    text=text\n",
    "    \n",
    "    # Remove punctuation if indicated in arguments to do so.\n",
    "    if punct == True:\n",
    "        punctuations = \"\"\"!()-[]{};:'\"\\,<>./?@#$%^&*_~\"\"\"\n",
    "        for x in text: \n",
    "            if x in punctuations: \n",
    "                text = text.replace(x, '')\n",
    "    \n",
    "    # Split the string into a list of words to compare against the\n",
    "    # spacy nlp.Defaults.stop_words list.\n",
    "    split_it = text.split()\n",
    "    stopped = [word.lower() for word in split_it \\\n",
    "               if word.lower() not in nlp.Defaults.stop_words]\n",
    "    \n",
    "    # Converting list back into a continuous string.\n",
    "    last_word = ''\n",
    "    for word in stopped:\n",
    "        last_word += (' ' + word)\n",
    "        \n",
    "    return last_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-setting columns and index after re-importing.\n",
    "df_good.columns = ['titles', 'scripts', 'good_or_bad']\n",
    "# df_good.set_index('titles', inplace=True)\n",
    "df_bad.columns = ['titles', 'scripts', 'good_or_bad']\n",
    "# df_bad.set_index('titles', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels, combining good and bad, and dropping missing scripts.\n",
    "df_good['good_or_bad'] = 1\n",
    "df_bad['good_or_bad'] = 0\n",
    "\n",
    "screenplays = pd.concat([df_good, df_bad])\n",
    "screenplays.columns = ['titles', 'scripts', 'good_or_bad']\n",
    "\n",
    "screenplays.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good:  1270\n",
      "Bad:  1514\n"
     ]
    }
   ],
   "source": [
    "print('Good: ', len(screenplays[screenplays['good_or_bad'] == 1]))\n",
    "print('Bad: ', len(screenplays[screenplays['good_or_bad'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting imported screenplays back to lists from strings\n",
    "screenplays.scripts = screenplays.scripts.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series with a list of lines for each screenplay.\n",
    "good_to_count = screenplays[screenplays['good_or_bad'] == 1]\n",
    "bad_to_count = screenplays[screenplays['good_or_bad'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single string of all good words.\n",
    "splice_scripts = ''\n",
    "for script in good_to_count['scripts']:\n",
    "    splice_scripts += ''.join(script)\n",
    "\n",
    "all_good_words = ''.join(splice_scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single string of all bad words.\n",
    "splice_scripts = ''\n",
    "for script in bad_to_count['scripts']:\n",
    "    splice_scripts += ''.join(script)\n",
    "\n",
    "all_bad_words = ''.join(splice_scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of all words lumped together and tokenized\n",
    "good_data = word_tokenize(all_good_words)\n",
    "bad_data = word_tokenize(all_bad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good words total:  14020073\n",
      "bad words total:  15477699\n"
     ]
    }
   ],
   "source": [
    "print('good words total: ', len(good_data))\n",
    "print('bad words total: ', len(bad_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good vocabulary:  172220\n",
      "bad vocabulary:  183840\n"
     ]
    }
   ],
   "source": [
    "print('good vocabulary: ', len(set(good_data)))\n",
    "print('bad vocabulary: ', len(set(bad_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good % vocab to total:  0.0123\n",
      "good % vocab to total:  0.0119\n"
     ]
    }
   ],
   "source": [
    "print('good % vocab to total: ', round(len(set(good_data)) / len(good_data),4))\n",
    "print('good % vocab to total: ', round(len(set(bad_data)) / len(bad_data),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Good # Words:  11039.427559055119\n",
      "Average Bad # Words:  10223.050858652576\n"
     ]
    }
   ],
   "source": [
    "# Total words divided by total number of sripts.\n",
    "print('Average Good # Words: ', len(good_data) / len(good_to_count))\n",
    "print('Average Bad # Words: ', len(bad_data) / len(bad_to_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave difference by words, good vs bad:  0.07985646473739089\n"
     ]
    }
   ],
   "source": [
    "print('Ave difference by words, good vs bad: ', ((len(good_data) / len(good_to_count)) - (len(bad_data) / len(bad_to_count)))\\\n",
    "    / (len(bad_data) / len(bad_to_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting punctuation and comparing good to bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_colons = good_data.count(':') / len(good_data)\n",
    "bad_colons = bad_data.count(':') / len(bad_data)\n",
    "good_semis = good_data.count(';') / len(good_data)\n",
    "bad_semis = bad_data.count(';') / len(bad_data)\n",
    "good_commas = good_data.count(',') / len(good_data)\n",
    "bad_commas = bad_data.count(',') / len(bad_data)\n",
    "good_elipses = good_data.count('...') / len(good_data)\n",
    "bad_elipses = bad_data.count('...') / len(bad_data)\n",
    "good_exclam = good_data.count('!') / len(good_data)\n",
    "bad_exclam = bad_data.count('!') / len(bad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good : ratio:  0.0016251698546790733\n",
      "Bad : ratio:  0.0014276669936532556\n",
      "Good ; ratio:  0.000047645971600861136\n",
      "Bad ; ratio:  0.00011416425658620187\n",
      "Good , ratio:  0.04718106674622878\n",
      "Bad , ratio:  0.04844324728113655\n",
      "Good ... ratio:  0.011329113621590985\n",
      "Bad ... ratio:  0.010440957664314314\n",
      "Good ! ratio:  0.010267706879985575\n",
      "Bad ! ratio:  0.0142683999734069\n"
     ]
    }
   ],
   "source": [
    "print('Good : ratio: ', good_colons)\n",
    "print('Bad : ratio: ', bad_colons)\n",
    "print('Good ; ratio: ', np.format_float_positional(good_semis))\n",
    "print('Bad ; ratio: ', np.format_float_positional(bad_semis))\n",
    "print('Good , ratio: ', good_commas)\n",
    "print('Bad , ratio: ', bad_commas)\n",
    "print('Good ... ratio: ', good_elipses)\n",
    "print('Bad ... ratio: ', bad_elipses)\n",
    "print('Good ! ratio: ', good_exclam)\n",
    "print('Bad ! ratio: ', bad_exclam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good-Bad % for :  0.1383395861246521\n",
      "Good-Bad % for ;  -0.5826542122237257\n",
      "Good-Bad % for ,  -0.026054829222797712\n",
      "Good-Bad % for ...  0.08506460669908276\n",
      "Good-Bad % for !  -0.2803883477388999\n"
     ]
    }
   ],
   "source": [
    "print('Good-Bad % for : ', (good_colons - bad_colons) / bad_colons)\n",
    "print('Good-Bad % for ; ', (good_semis - bad_semis) / bad_semis)\n",
    "print('Good-Bad % for , ', (good_commas - bad_commas) / bad_commas)\n",
    "print('Good-Bad % for ... ', (good_elipses - bad_elipses) / bad_elipses)\n",
    "print('Good-Bad % for ! ', (good_exclam - bad_exclam) / bad_exclam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad scripts on average use 28% more exclamation marks and 58% more semicolons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "splice_scripts = ''\n",
    "for script in screenplays['scripts']:\n",
    "    splice_scripts += ''.join(script)\n",
    "\n",
    "all_words = ''.join(splice_scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for script in screenplays['scripts']:\n",
    "    temp.append(''.join(script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has each script as one long string inside of its cell, \n",
    "# as opposed with a list of lines.\n",
    "screenplays['all_together_now'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = word_tokenize(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for # of unique tokens so I know roughly how many to play with when modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278462"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will be used in an apply function remove the stop words for purposes further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a1443a7a4a4b00b30991c02d4837d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2784), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "screenplays['no_stop'] = screenplays['all_together_now']\\\n",
    "    .progress_apply(stop_it, punct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c617443a44244b2b8caed964c21e658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2784), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "screenplays['just_words'] = screenplays['all_together_now']\\\n",
    "    .progress_apply(stop_it, punct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rottentomatoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rotten_df.drop(rotten_df['Unnamed 0'], inplace=True, axis=1)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for script in rotten_df.scripts:\n",
    "    temp.append(''.join(script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has each script as one long string inside of its cell, \n",
    "# as opposed with a list of lines.\n",
    "rotten_df['all_together_now'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will be used in an apply function remove the stop words for purposes further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8392cc966e4064959a4af424108416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9f2ae3ec5b497ebf9f2c75a01a4374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rotten_df['no_stop'] = rotten_df['all_together_now']\\\n",
    "    .progress_apply(stop_it, punct=False)\n",
    "\n",
    "rotten_df['just_words'] = rotten_df['all_together_now']\\\n",
    "    .progress_apply(stop_it, punct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_df.rename(columns={'.':'PER'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>titles_formatted</th>\n",
       "      <th>rotten_scores</th>\n",
       "      <th>scripts</th>\n",
       "      <th>all_together_now</th>\n",
       "      <th>no_stop</th>\n",
       "      <th>just_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>twisted</td>\n",
       "      <td>twisted</td>\n",
       "      <td>1</td>\n",
       "      <td>['\\n\\n                        I can hear your ...</td>\n",
       "      <td>['\\n\\n                        I can hear your ...</td>\n",
       "      <td>['\\n\\n hear heart beating.', ' sounds like li...</td>\n",
       "      <td>nn hear heart beating sounds like little anim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>kings_ransom</td>\n",
       "      <td>kings-ransom</td>\n",
       "      <td>1</td>\n",
       "      <td>['\\n\\n                        Wake up, Chicago...</td>\n",
       "      <td>['\\n\\n                        Wake up, Chicago...</td>\n",
       "      <td>['\\n\\n wake up, chicago.', ' morning man...',...</td>\n",
       "      <td>nn wake chicago morning man getting way 810 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>getting_even_with_dad</td>\n",
       "      <td>getting-even-with-dad</td>\n",
       "      <td>2</td>\n",
       "      <td>[\"\\n\\n                        (MONEY THAT'S WH...</td>\n",
       "      <td>[\"\\n\\n                        (MONEY THAT'S WH...</td>\n",
       "      <td>[\"\\n\\n (money that's wan playing)\", ' best th...</td>\n",
       "      <td>nn money thats wan playing best things life f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>passion_play</td>\n",
       "      <td>passion-play</td>\n",
       "      <td>2</td>\n",
       "      <td>['\\n\\n                        Hey, Billy.', \" ...</td>\n",
       "      <td>['\\n\\n                        Hey, Billy.', \" ...</td>\n",
       "      <td>['\\n\\n hey, billy.', \" it's thursday.\", ' com...</td>\n",
       "      <td>nn hey billy thursday come tomorrow actually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>half_past_dead</td>\n",
       "      <td>half-past-dead</td>\n",
       "      <td>2</td>\n",
       "      <td>['\\n\\n                        So, Nick...', ' ...</td>\n",
       "      <td>['\\n\\n                        So, Nick...', ' ...</td>\n",
       "      <td>['\\n\\n so, nick...', ' ...this it?', ' promis...</td>\n",
       "      <td>nn nick promised lets plane catch know sonny ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>feardotcom</td>\n",
       "      <td>feardotcom</td>\n",
       "      <td>2</td>\n",
       "      <td>['\\n\\n                        No!', ' Damn.', ...</td>\n",
       "      <td>['\\n\\n                        No!', ' Damn.', ...</td>\n",
       "      <td>['\\n\\n no!', ' damn.', ' thanks present, benn...</td>\n",
       "      <td>nn damn thanks present bennie guess business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>the_darkness</td>\n",
       "      <td>darkness-the</td>\n",
       "      <td>2</td>\n",
       "      <td>['\\n\\n                        Now, I want you ...</td>\n",
       "      <td>['\\n\\n                        Now, I want you ...</td>\n",
       "      <td>['\\n\\n now, want try tell us', ' happened.', ...</td>\n",
       "      <td>nn want try tell happened remember cant cant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>jack_and_jill</td>\n",
       "      <td>jack-and-jill</td>\n",
       "      <td>2</td>\n",
       "      <td>['\\n\\n                        And we were born...</td>\n",
       "      <td>['\\n\\n                        And we were born...</td>\n",
       "      <td>['\\n\\n born', ' september 15...', \" and... sh...</td>\n",
       "      <td>nn born september 15 shes older older twin im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bless_the_child</td>\n",
       "      <td>bless-the-child</td>\n",
       "      <td>2</td>\n",
       "      <td>[\"\\n\\n                        - [ Bell Ringing...</td>\n",
       "      <td>[\"\\n\\n                        - [ Bell Ringing...</td>\n",
       "      <td>[\"\\n\\n - [ bell ringing ]|- ~ 'tis season jol...</td>\n",
       "      <td>nn bell ringing | tis season jolly fa la la l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>battlefield_earth</td>\n",
       "      <td>battlefield-earth</td>\n",
       "      <td>2</td>\n",
       "      <td>['\\n\\n                        The entire tribe...</td>\n",
       "      <td>['\\n\\n                        The entire tribe...</td>\n",
       "      <td>['\\n\\n entire tribe not|be endangered. . .', ...</td>\n",
       "      <td>nn entire tribe not|be endangered defiance of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   titles       titles_formatted  rotten_scores  \\\n",
       "40                twisted                twisted              1   \n",
       "41           kings_ransom           kings-ransom              1   \n",
       "42  getting_even_with_dad  getting-even-with-dad              2   \n",
       "43           passion_play           passion-play              2   \n",
       "44         half_past_dead         half-past-dead              2   \n",
       "45             feardotcom             feardotcom              2   \n",
       "46           the_darkness           darkness-the              2   \n",
       "47          jack_and_jill          jack-and-jill              2   \n",
       "48        bless_the_child        bless-the-child              2   \n",
       "49      battlefield_earth      battlefield-earth              2   \n",
       "\n",
       "                                              scripts  \\\n",
       "40  ['\\n\\n                        I can hear your ...   \n",
       "41  ['\\n\\n                        Wake up, Chicago...   \n",
       "42  [\"\\n\\n                        (MONEY THAT'S WH...   \n",
       "43  ['\\n\\n                        Hey, Billy.', \" ...   \n",
       "44  ['\\n\\n                        So, Nick...', ' ...   \n",
       "45  ['\\n\\n                        No!', ' Damn.', ...   \n",
       "46  ['\\n\\n                        Now, I want you ...   \n",
       "47  ['\\n\\n                        And we were born...   \n",
       "48  [\"\\n\\n                        - [ Bell Ringing...   \n",
       "49  ['\\n\\n                        The entire tribe...   \n",
       "\n",
       "                                     all_together_now  \\\n",
       "40  ['\\n\\n                        I can hear your ...   \n",
       "41  ['\\n\\n                        Wake up, Chicago...   \n",
       "42  [\"\\n\\n                        (MONEY THAT'S WH...   \n",
       "43  ['\\n\\n                        Hey, Billy.', \" ...   \n",
       "44  ['\\n\\n                        So, Nick...', ' ...   \n",
       "45  ['\\n\\n                        No!', ' Damn.', ...   \n",
       "46  ['\\n\\n                        Now, I want you ...   \n",
       "47  ['\\n\\n                        And we were born...   \n",
       "48  [\"\\n\\n                        - [ Bell Ringing...   \n",
       "49  ['\\n\\n                        The entire tribe...   \n",
       "\n",
       "                                              no_stop  \\\n",
       "40   ['\\n\\n hear heart beating.', ' sounds like li...   \n",
       "41   ['\\n\\n wake up, chicago.', ' morning man...',...   \n",
       "42   [\"\\n\\n (money that's wan playing)\", ' best th...   \n",
       "43   ['\\n\\n hey, billy.', \" it's thursday.\", ' com...   \n",
       "44   ['\\n\\n so, nick...', ' ...this it?', ' promis...   \n",
       "45   ['\\n\\n no!', ' damn.', ' thanks present, benn...   \n",
       "46   ['\\n\\n now, want try tell us', ' happened.', ...   \n",
       "47   ['\\n\\n born', ' september 15...', \" and... sh...   \n",
       "48   [\"\\n\\n - [ bell ringing ]|- ~ 'tis season jol...   \n",
       "49   ['\\n\\n entire tribe not|be endangered. . .', ...   \n",
       "\n",
       "                                           just_words  \n",
       "40   nn hear heart beating sounds like little anim...  \n",
       "41   nn wake chicago morning man getting way 810 w...  \n",
       "42   nn money thats wan playing best things life f...  \n",
       "43   nn hey billy thursday come tomorrow actually ...  \n",
       "44   nn nick promised lets plane catch know sonny ...  \n",
       "45   nn damn thanks present bennie guess business ...  \n",
       "46   nn want try tell happened remember cant cant ...  \n",
       "47   nn born september 15 shes older older twin im...  \n",
       "48   nn bell ringing | tis season jolly fa la la l...  \n",
       "49   nn entire tribe not|be endangered defiance of...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_df[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotten_df.dropna(inplace=True)\n",
    "# screenplays.dropna(inplace=True)\n",
    "\n",
    "rotten_df = rotten_df.drop_duplicates(subset=['titles']).copy()\n",
    "screenplays = screenplays.drop_duplicates(['titles']).copy()\n",
    "\n",
    "screenplays.to_csv('screenplays_scrub.csv')\n",
    "rotten_df.to_csv('rotten_df_scrub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "168.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
