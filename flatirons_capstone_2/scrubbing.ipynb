{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "from ast import literal_eval\n",
    "from importlib import reload\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Importing my own functions file.\n",
    "import functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrubbing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading back in data that was created in 'obtaining' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had intended to use files directly from the 'obtain' notebook to be cleaner,\n",
    "# but I can't get back into the screenplay site, so I'll have to improvise.\n",
    "# df_good = pd.read_csv('df_good_obtain.csv')\n",
    "# df_bad = pd.read_csv('df_bad_obtain.csv')\n",
    "# rotten_df = pd.read_csv('rotten_df_obtain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good = pd.read_csv('../project_resources/df_good.csv', index_col=False)\n",
    "df_bad = pd.read_csv('../project_resources/df_bad.csv', index_col=False)\n",
    "rotten_df = pd.read_csv('../project_resources/rotten_df.csv', index_col=0)\n",
    "\n",
    "rotten_df.columns = ['titles', 'titles_formatted', 'rotten_scores', \n",
    "                     'scripts', 'all_together_now', 'no_stop', 'just_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metacritic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-setting columns and index after re-importing.\n",
    "df_good.columns = ['titles', 'scripts', 'good_or_bad']\n",
    "df_bad.columns = ['titles', 'scripts', 'good_or_bad']\n",
    "\n",
    "# Adding labels, combining good and bad, and dropping missing scripts.\n",
    "df_good['good_or_bad'] = 1\n",
    "df_bad['good_or_bad'] = 0\n",
    "\n",
    "screenplays = pd.concat([df_good, df_bad])\n",
    "screenplays.columns = ['titles', 'scripts', 'good_or_bad']\n",
    "\n",
    "screenplays.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of good screeenplays:  1270\n",
      "# of bad screenplays:  1514\n"
     ]
    }
   ],
   "source": [
    "print('# of good screeenplays: ', len(screenplays[screenplays['good_or_bad'] == 1]))\n",
    "print('# of bad screenplays: ', len(screenplays[screenplays['good_or_bad'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting imported screenplays back to lists from strings\n",
    "screenplays.scripts = screenplays.scripts.apply(literal_eval)\n",
    "\n",
    "# Series with a list of lines for each screenplay.\n",
    "good_to_count = screenplays[screenplays['good_or_bad'] == 1]\n",
    "bad_to_count = screenplays[screenplays['good_or_bad'] == 0]\n",
    "\n",
    "# Single string of all good words.\n",
    "splice_scripts = ''\n",
    "for script in good_to_count['scripts']:\n",
    "    splice_scripts += ''.join(script)\n",
    "\n",
    "all_good_words = ''.join(splice_scripts)\n",
    "\n",
    "# Single string of all bad words.\n",
    "splice_scripts = ''\n",
    "for script in bad_to_count['scripts']:\n",
    "    splice_scripts += ''.join(script)\n",
    "\n",
    "all_bad_words = ''.join(splice_scripts)\n",
    "\n",
    "# Lists of all words lumped together and tokenized\n",
    "good_data = word_tokenize(all_good_words)\n",
    "bad_data = word_tokenize(all_bad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating some simple word metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good words total:  14020073\n",
      "bad words total:  15477699\n",
      "--------------------------------------------------------------------------------\n",
      "good vocabulary:  172220\n",
      "bad vocabulary:  183840\n",
      "--------------------------------------------------------------------------------\n",
      "good % vocab to total:  0.0123\n",
      "good % vocab to total:  0.0119\n",
      "--------------------------------------------------------------------------------\n",
      "Average Good # Words:  11039.427559055119\n",
      "Average Bad # Words:  10223.050858652576\n",
      "--------------------------------------------------------------------------------\n",
      "Ave difference by words, good vs bad:  0.08\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('good words total: ', len(good_data))\n",
    "print('bad words total: ', len(bad_data))\n",
    "print('----'*20)\n",
    "\n",
    "print('good vocabulary: ', len(set(good_data)))\n",
    "print('bad vocabulary: ', len(set(bad_data)))\n",
    "print('----'*20)\n",
    "\n",
    "print('good % vocab to total: ', round(len(set(good_data)) / len(good_data),4))\n",
    "print('good % vocab to total: ', round(len(set(bad_data)) / len(bad_data),4))\n",
    "print('----'*20)\n",
    "\n",
    "# Total words divided by total number of sripts.\n",
    "print('Average Good # Words: ', len(good_data) / len(good_to_count))\n",
    "print('Average Bad # Words: ', len(bad_data) / len(bad_to_count))\n",
    "print('----'*20)\n",
    "\n",
    "print('Ave difference by words, good vs bad: ', \n",
    "      round(((len(good_data) / len(good_to_count)) \\\n",
    "       - (len(bad_data) / len(bad_to_count))) / (len(bad_data) \\\n",
    "                                                 / len(bad_to_count)),2))\n",
    "print('----'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting punctuation and comparing good to bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good ':' ratio:  0.001625\n",
      "Bad ':' ratio:  0.001428\n",
      "Good-Bad % for ':' 0.14\n",
      "--------------------------------------------------\n",
      "Good ';' ratio:  0.000048\n",
      "Bad ';' ratio:  0.000114\n",
      "Good-Bad % for ';' -0.58\n",
      "--------------------------------------------------\n",
      "Good ',' ratio:  0.047181\n",
      "Bad ',' ratio:  0.048443\n",
      "Good-Bad % for ',' -0.03\n",
      "--------------------------------------------------\n",
      "Good '...' ratio:  0.011329\n",
      "Bad '...' ratio:  0.010441\n",
      "Good-Bad % for '...' 0.09\n",
      "--------------------------------------------------\n",
      "Good '!' ratio:  0.010268\n",
      "Bad '!' ratio:  0.014268\n",
      "Good-Bad % for '!' -0.28\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for p in [':', ';', ',', '...', '!']:\n",
    "    good_p = good_data.count(p) / len(good_data)\n",
    "    bad_p = bad_data.count(p) / len(bad_data)\n",
    "    print(f'Good \\'{p}\\' ratio: ', np.format_float_positional(round(good_p, 6)))\n",
    "    print(f'Bad \\'{p}\\' ratio: ', np.format_float_positional(round(bad_p,6)))\n",
    "    print(f'Good-Bad % for \\'{p}\\'', round((good_p - bad_p) / bad_p,2))\n",
    "    print('-----'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad scripts on average use 28% more exclamation marks and 58% more semicolons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now creating additional columns for scripts in different formats. Right now, each script line is an element of a list. Breaking those apart into one long string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "splice_scripts = ''\n",
    "for script in screenplays['scripts']:\n",
    "    splice_scripts += ''.join(script)\n",
    "\n",
    "all_words = ''.join(splice_scripts)\n",
    "\n",
    "temp = []\n",
    "for script in screenplays['scripts']:\n",
    "    temp.append(''.join(script))\n",
    "\n",
    "# This has each script as one long string inside of its cell, \n",
    "# as opposed with a list of lines.\n",
    "screenplays['all_together_now'] = temp\n",
    "\n",
    "data = word_tokenize(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for # of unique tokens so I know roughly how many to play with when modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278462"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will be used in an apply function remove the stop words for purposes further down. One will keep punctuation and one will remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895e1566ee8a4acfa7e5aa3b14ca3b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2784), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06d9cc34429450db3f9b9306c51e0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2784), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "screenplays['no_stop'] = screenplays['all_together_now']\\\n",
    "    .progress_apply(fun.stop_it, punct=False)\n",
    "\n",
    "screenplays['just_words'] = screenplays['all_together_now']\\\n",
    "    .progress_apply(fun.stop_it, punct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rottentomatoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for script in rotten_df.scripts:\n",
    "    temp.append(''.join(script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has each script as one long string inside of its cell, \n",
    "# as opposed with a list of lines.\n",
    "rotten_df['all_together_now'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function again for rotten_df this time to remove stop words for one columns of scripts and remove stop words plus punctuation for another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7512eb3027e448aabadbddc5ae0a9f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e50b887be04435a0f4dfa4d3cc4455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rotten_df['no_stop'] = rotten_df['all_together_now']\\\n",
    "    .progress_apply(fun.stop_it, punct=False)\n",
    "\n",
    "rotten_df['just_words'] = rotten_df['all_together_now']\\\n",
    "    .progress_apply(fun.stop_it, punct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to rename the period since it causes problems later on.\n",
    "rotten_df.rename(columns={'.':'PER'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotten_df.dropna(inplace=True)\n",
    "# screenplays.dropna(inplace=True)\n",
    "\n",
    "rotten_df = rotten_df.drop_duplicates(subset=['titles']).copy()\n",
    "screenplays = screenplays.drop_duplicates(['titles']).copy()\n",
    "\n",
    "screenplays.to_csv('screenplays_scrub.csv')\n",
    "rotten_df.to_csv('rotten_df_scrub.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "168.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
